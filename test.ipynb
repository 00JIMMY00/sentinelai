{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hoda\n"
     ]
    }
   ],
   "source": [
    "print('hoda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number of Real: 6978\n",
      " Number of Fake: 6978\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "real_count = len(os.listdir(\"dataset/real\"))\n",
    "fake_count = len(os.listdir(\"dataset/fake\"))\n",
    "\n",
    "print(\"  Number of Real:\", real_count)\n",
    "print(\" Number of Fake:\", fake_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (13956, 20)\n",
      "Shape of y (labels): (13956,)\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Import Libraries\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "real_path = \"dataset/real\"\n",
    "fake_path = \"dataset/fake\"\n",
    "\n",
    "X = []   # features\n",
    "y = []   # labels\n",
    "\n",
    "#Step 2: Preprocessing\n",
    "\n",
    "# Function to extract MFCC features\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000)   # load audio\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)  # extract MFCCs\n",
    "    mfcc = np.mean(mfcc.T, axis=0)  # take mean across time to reduce size\n",
    "    return mfcc\n",
    "\n",
    "# Process real audio (label = 0)\n",
    "for file in os.listdir(real_path):\n",
    "    file_path = os.path.join(real_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    X.append(features)\n",
    "    y.append(0)\n",
    "\n",
    "# Process fake audio (label = 1)\n",
    "for file in os.listdir(fake_path):\n",
    "    file_path = os.path.join(fake_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    X.append(features)\n",
    "    y.append(1)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Shape of X (features):\", X.shape)\n",
    "print(\"Shape of y (labels):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-159.15465  ,   69.013855 ,  -24.30139  , ...,   -1.6907821,\n",
       "         -12.04648  ,   -4.170325 ],\n",
       "       [-181.14969  ,  101.52206  ,  -16.545155 , ...,   -2.3432863,\n",
       "          -8.728118 ,   -3.4083452],\n",
       "       [-178.86577  ,   70.01746  ,  -14.008171 , ...,   -7.242671 ,\n",
       "         -10.442345 ,   -8.342333 ],\n",
       "       ...,\n",
       "       [-203.2837   ,  101.944984 ,   28.760866 , ...,    3.6852238,\n",
       "          -8.911958 ,   -5.1887226],\n",
       "       [-185.3693   ,   50.673904 ,   -9.381918 , ...,   -2.489033 ,\n",
       "         -13.970686 ,   -4.413645 ],\n",
       "       [-111.33813  ,   95.25883  ,  -30.96078  , ...,  -10.128829 ,\n",
       "         -14.044191 ,    0.7977651]], shape=(13956, 20), dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X.npy\", X)\n",
    "np.save(\"y.npy\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (11164, 20) (11164,)\n",
      "Testing set size: (2792, 20) (2792,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7987106017191977\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      1396\n",
      "           1       0.79      0.82      0.80      1396\n",
      "\n",
      "    accuracy                           0.80      2792\n",
      "   macro avg       0.80      0.80      0.80      2792\n",
      "weighted avg       0.80      0.80      0.80      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train a simple Logistic Regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Reshape for CNN (samples, timesteps, features)\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn  = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # binary classification (real=0, fake=1)\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5847 - loss: 1.0530 - val_accuracy: 0.7633 - val_loss: 0.5895\n",
      "Epoch 2/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.5736 - val_accuracy: 0.7962 - val_loss: 0.4796\n",
      "Epoch 3/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.5088 - val_accuracy: 0.8302 - val_loss: 0.4251\n",
      "Epoch 4/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7891 - loss: 0.4533 - val_accuracy: 0.8592 - val_loss: 0.3516\n",
      "Epoch 5/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4159 - val_accuracy: 0.8711 - val_loss: 0.3139\n",
      "Epoch 6/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3782 - val_accuracy: 0.8840 - val_loss: 0.2726\n",
      "Epoch 7/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8463 - loss: 0.3492 - val_accuracy: 0.8994 - val_loss: 0.2541\n",
      "Epoch 8/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8578 - loss: 0.3364 - val_accuracy: 0.9140 - val_loss: 0.2272\n",
      "Epoch 9/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.3114 - val_accuracy: 0.9259 - val_loss: 0.2086\n",
      "Epoch 10/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.2987 - val_accuracy: 0.9330 - val_loss: 0.1961\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - accuracy: 0.9330 - loss: 0.1961\n",
      "Test Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train\n",
    "history = model.fit(X_train_cnn, y_train, validation_data=(X_test_cnn, y_test),\n",
    "                    epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"deepfake_audio_cnn.h5\")\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"deepfake_audio_cnn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x308536ad0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGwCAYAAAA0bWYRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOHpJREFUeJzt3Ql4VNX5x/HfJCEJWyCsYV9UVhEUlOKCWCgoFkWl/lWqqBRbBBRQtioIblhUQBTBHbXgVoUqKorQggKCgCgiIihK2FWWsJh15v+cE2dkgKkJM8kkc74fn/tMZu6SG5rmvvd933Oux+fz+QQAAJwVF+0TAAAA0UUwAACA4wgGAABwHMEAAACOIxgAAMBxBAMAADiOYAAAAMclqBTzer3avn27KlasKI/HE+3TAQAUkpnq5sCBA6pdu7bi4oru/jQzM1PZ2dlhHycxMVHJycmKNaU6GDCBQL169aJ9GgCAMKWnp6tu3bpFFgg0alBBO3fnhX2stLQ0bd68OeYCglIdDJiMgLF5VX1VrEDFA7GpV7M20T4FoMjk+nL0kd4O/D0vCiYjYAKB71c1VErFE79WZBzwqkHb7+zxCAZKEH9pwAQC4fwPDJRkCZ4y0T4FoGj5fv17XpQqVPTY5UR5Fbvl6FIdDAAAUFB5Pq/yfOHtH6sIBgAATvDKZ5dw9o9V5NYBAHAcmQEAgBO89r/w9o9VBAMAACfk+Xx2CWf/WEWZAAAAx5EZAAA4gQbC0AgGAABOMBfzPIKB46JMAACA48gMAACcQJkgNIIBAIATGE0QGmUCAAAcR2YAAOAEM2VQeJMOxS6CAQCAE/LCHE2QR88AAAClm3liYXhPLVTMomcAAADHkRkAADiBnoHQCAYAAE7wyqM8ecLaP1ZRJgAAwHFkBgAATvD68pdw9o9VBAMAACfkhVkmyKNMAAAAYhWZAQCAE8gMhEYwAABwgtfnsUs4+8cqygQAADiOzAAAwAmUCUIjMwAAcEKe4sJeCmPx4sXq0aOHateuLY/Hozlz5gTW5eTkaMSIEWrVqpXKly9vt7nuuuu0ffv2oGPs2bNHvXv3VkpKiipXrqy+ffvq4MGDQdt8/vnnOu+885ScnKx69eppwoQJKiyCAQCAE3y/9Ayc6OIrZM/AoUOH1Lp1a02dOvWYdYcPH9bq1as1evRo+/rGG29ow4YNuuSSS4K2M4HAunXrNH/+fM2dO9cGGDfddFNgfUZGhrp27aoGDRpo1apVevDBBzV27Fg9+eSThTpXygQAABSBiy66yC7HU6lSJXuBP9Jjjz2ms846S1u2bFH9+vW1fv16zZs3T5988onatWtnt3n00UfVvXt3PfTQQzabMHPmTGVnZ+vZZ59VYmKiWrZsqTVr1mjixIlBQcNvITMAAHCqZyCcxX83fuSSlZWlSNi/f78tJ5hygLFs2TL7tT8QMLp06aK4uDgtX748sE3Hjh1tIODXrVs3m2XYu3dvgb83wQAAwAl5vriwF8PU5c2dvX8ZP368wpWZmWl7CK6++mrbH2Ds3LlTNWrUCNouISFBVapUsev829SsWTNoG/97/zYFQZkAAIBCSE9PD1ywjaSkJIXDNBNeeeWV8vl8mjZtmqKBYAAA4ATzCGJvGAlxr/KfVGQCgSODgUgEAt9//70WLlwYdNy0tDTt3r07aPvc3Fw7wsCs82+za9euoG387/3bFARlAgCAEyLVMxAp/kBg48aN+uCDD1S1atWg9R06dNC+ffvsKAE/EzB4vV61b98+sI0ZYWCO5WcaE5s2barU1NQCnwvBAAAARcDMB2A6+81ibN682X5tRguYi3evXr20cuVKOyIgLy/P1vjNYkYHGM2bN9eFF16ofv36acWKFVqyZIkGDhyoq666yo4kMK655hrbPGjmHzBDEF955RU98sgjGjp0aKHOlTIBAMAJRzYBntj+vkJtby70F1xwQeC9/wLdp08fOxfAm2++ad+3adMmaL///Oc/6tSpk/3aBAomAOjcubMdRXDFFVdoypQpgW1NA+P777+vAQMGqG3btqpWrZrGjBlTqGGFBsEAAMChnoEwHlSkwu1rLuimKTCU/7XOz4wcmDVr1v/c5rTTTtOHH36ocFAmAADAcWQGAABO8J7A8wWON5ogFhEMAACcUNw9A6UJwQAAwJnMQCTmGYhF9AwAAOA4MgMAACfk+Tx2CWf/WEUwAABwQl6YDYR5lAkAAECsIjMAAHCC1xdnlxPf36dYRTAAAHACZYLQKBMAAOA4MgMAACd4wxwR4FXsIhgAADgh/EmH4hSrYvcnAwAABUJmAADghPCfTRCnWEUwAABwglceu4Szf6wiGAAAOIHMQGix+5MBAIACITMAAHBC+JMOxSlWEQwAAJzg9XnsEs7+sSp2wxwAAFAgZAYAAE4wkwaFk+r3xvD9M8EAAMAJ4T+1ME6xKnZ/MgAAUCBkBgAATsiTxy7h7B+rCAYAAE6gTBBa7P5kAACgQMgMAACckBdmqj9PsYtgAADgBMoEoREMAACcwIOKQovdnwwAABQImQEAgBN88sgbRs+Aj6GFAACUbpQJQovdnwwAABQImQEAgBN4hHFoBAMAACfkhfnUwrwYTqbH7k8GAAAKhMwAAMAJlAlCIxgAADjBqzi7hLN/rIrdnwwAABQImQEAgBPyfB67hLN/rCIYAAA4gZ6B0AgGAABO8IX51EIfMxACAIBYRWYAAOCEPHnsEs7+sYpgAADgBK8vvLq/16eYRZkAAADHkRlwzNqPK+j1aTW1aW1Z7dmVqDuf+UZnX7jfrsvNkV6YUFufLKyknd8nqnxKntqce0A3/H27qqblBI5h9n32vjra+Fk5xcVJ51y8T/3u2qqy5b2Bbb5eU07P3V9bm9aWk8cjNWlzWDfesU2NW/4clZ8bOFLZ8nnqM3yH/d2vXDVX36wrq2lj6urrz8rZ9cnl8tT37zvU4cL9Sqmcq53pifr3s9X19ovVon3qCIM3zAZCLw2EiBWZh+PUqMVh3Xxf+jHrsn6Osxfvq2/doUfnfaU7n/pWW79N1rgbGge2+WlnGf39qlNUu2GWJr21QffM3KTvNyRr4uAGgW1+PhSn0b1PVvU6OXabB2d/bf/4ms9MwAFE25CH0nXGeQc14ZYG+luXZlq1qKIeeHmTqqZl2/V/vWu72nXK0IRB9dWvUzPNfrq6Bty7Vb/7Q37gjNLJK0/YS6wqEcHA1KlT1bBhQyUnJ6t9+/ZasWJFtE8pZp35+wz1GbFDZ1907B+18ile3f/yJnW8ZJ/qnpylZm0P6+Z707Xp8/Lava2M3WbFBylKSPDp5vvT7Tbmjn/gA1u05J1Ubd+cZLdJ35SsA/sSdO3t2+02DZpm6pqhO7T3hzLavTV/GyBaEpO9Orf7Pj19Xy19sbyCtn+XpH9OrGVf/3jdT3abFu0Oaf6/qujzZRW1a2uS3p1ZTd9+WVZNTz8c7dMHYjMYeOWVVzR06FDdddddWr16tVq3bq1u3bpp9+7d0T41SDqUES+Px6cKKXn2fU52nBLK+Gx5wC8pOb+rZt2K8va17kmZSknN1XsvV1NOtkdZP3v0/kvVVO+Un1WzXlZ0fhDgF/HxPsUnSNlZwX/+sjLj1PLMg/brL1eWt1mA/EyBT63PPqA6jbNsBgGlfwbCcJbCWLx4sXr06KHatWvL4/Fozpw5Qet9Pp/GjBmjWrVqqWzZsurSpYs2btwYtM2ePXvUu3dvpaSkqHLlyurbt68OHsz/PfX7/PPPdd5559kb6nr16mnChAkqdcHAxIkT1a9fP91www1q0aKFpk+frnLlyunZZ5+N9qk5LzvTo+fur6Pze+5VuYr5/QCtzzlg7/D/Na2GvdAf2BdvewOMPbvzswflKnj1wL++1n/eSNVlJ7XRFU3aaNV/U3T3P7+xf4SBaPr5ULy+XFlO19y6U1Vq5iguzqffX75HzdseUpWauXabx0fX0ZaNyZq16ku9/d1nuvef32rqHXVtJgGlv2cgnKUwDh06ZG9wTfb7eMxFe8qUKfa6t3z5cpUvX97eDGdmZga2MYHAunXrNH/+fM2dO9cGGDfddFNgfUZGhrp27aoGDRpo1apVevDBBzV27Fg9+eSThTrXqP5pzs7Otic/atSowGdxcXE2Olq2bNkx22dlZdnlyH8EFA1T2x//t0by+aSB47cEPjcp/6GTv9PT4+pqxvg6iov36dIbf1BqdfNHNX8bkwmYfHsDm2odMfU7efOk16fX1NjrTtLkt79SUtkYHp+DUsH0Cgx9eIteWr1OebmmKbac/jsnVaecll8GuPSGH9XsjMMac30j7d6aqFbtD2rAfVv1064y+vRDsgOuyzjq2pOUlGSXo1100UV2OR6TFZg8ebLuvPNOXXrppfazF154QTVr1rQZhKuuukrr16/XvHnz9Mknn6hdu3Z2m0cffVTdu3fXQw89ZDMOM2fOtNdScwOdmJioli1bas2aNfZG+8igoURnBn788Ufl5eXZH/5I5v3OnTuP2X78+PGqVKlSYDHpEBRVINDY/hG876WNgayA3wWX7dXMNWv14qq1euWLz9X7th3a/1OC0urnB2r/nVNFu9MTNWTS97anwPQeDJ/6nXZuSdTH71eO0k8F/GrH90ka1usUXXJyK/35zJa65Y9NbPlrx5Yk21Nw/cgdenJcbS2fX0mb15fVmzOqa9GbldXrr5QvSzPbBOgLY1F+mcBce468FplrU2Ft3rzZXufMza+fOZbpm/PfDJtXUxrwBwKG2d7cNJtMgn+bjh072kDAz2QXNmzYoL179xb4fEpV0tZkEEx/wZHRGQFB0QQCphnwgdc2KqVKfq/A8aRWz0+pvv9yVZVJ8ur0jgcCoxI8cbJDCv1MKta89wbHFUBUZf0cb5cKlXLV9vwMPX1fbdsgWybRJ683uD5s3pvfa5RevjBHBPh+2Tc9Pd3W8P2OlxX4Lf4b3v91M2xea9SoEbQ+ISFBVapUCdqmUaNGxxzDvy41NbXkBwPVqlVTfHy8du3aFfS5eZ+WlnbM9qFSMSg4M+zP3/Vv7NqSpG++KKuKqbmqUiNH99/U2KZMxz7/jfLyTB9A/q9Ixcp59g+k8dZz1dW83UEll/PalOmz99TV9X/fpgqV8gOH0ztm6Jl76+jxv9dTjxt/kM8rvfpYTcUn5DdiAdFmLvwmOE3/Jkl1GmbrL6O3Kf2bZL3/SlXl5Xr02dLy6nfndts3s2trok7rcFBdrtijJ++uE+1TRwl4amFKSkpQMBALohoMmLRG27ZttWDBAvXs2dN+5vV67fuBAwdG89RilpkoaOSfmgTePzWurn3t8qefbLrfn8Yf2LV50H4PvPa1Tjs7v4N1w6fl9M+Haunnw3Gqd1KmBv5jizr32hPYtt7JWbprxjeaNbGWbrukib2bOqnlYd3zz02BBi0gmsyEWjeM3KFqtXJsE+ySdyrruX/UsoGAMf7mhrpx1A6NeHSLKlbO1e5tiZoxoZbmvlA12qeOGJH2yw2vufk1own8zPs2bdoEtjl6ZF1ubq4dYeDf37we74b6yO9RKsoEJu3fp08fWxM566yzbEOF6cA0owsQeeaC/s621SHX/691frdP+f43tzmj4wG7ACXR4rdS7RKKGTHz8ND6xXpOcGsGwkaNGtmLtbn59V/8Tenb9AL079/fvu/QoYP27dtnG+3NjbOxcOFCe9Nsegv829xxxx3KyclRmTL5I7rMyIOmTZsWuERQIoKB//u//9MPP/xgx1qa+ob5RzHdk0fXUQAAKAllgoIy8wFs2rQpqGnQdPqbmn/9+vU1ePBg3XvvvTrllFNscDB69Gg7QsCfKW/evLkuvPBCO/zeDD80F3yTNTcjDcx2xjXXXKNx48bZ+QdGjBihL774Qo888ogmTZqkwoh6MGCYH46yAAAglqxcuVIXXHBB4L2/Ad5kw2fMmKHhw4fbTLgZAmgyAOeee669GTaTB/mZoYPm+ti5c2c7iuCKK66wcxMcOQLh/fff14ABA2z2wPTimZvrwgwrNDw+M9ixlDIpFfMP8eOGhkqpSJsvYlP3uvnpQSAW5fpy9F/fHO3fv7/ImvL814oe7/dVmfK/DsErrJxD2Xqr6zNFeq7RUiIyAwAAxFqZoDThdhoAAMeRGQAAOIHMQGgEAwAAJxAMhEaZAAAAx5EZAAA4gcxAaAQDAAAnmHH04T2oKHYRDAAAnEBmIDR6BgAAcByZAQCAE8gMhEYwAABwAsFAaJQJAABwHJkBAIATyAyERjAAAHCCz+exSzj7xyrKBAAAOI7MAADACWbCoXAmHfKGsW9JRzAAAHACPQOhUSYAAMBxZAYAAE6ggTA0ggEAgBMoE4RGMAAAcAKZgdDoGQAAwHFkBgAATjB39uGk+n0xnBkgGAAAOMFnL+jh7R+rKBMAAOA4MgMAACeYGQTNf+HsH6sIBgAATmA0QWiUCQAAcByZAQCAE8xIAg+TDh0XwQAAwAlmJEFYowl8ilmUCQAAcByZAQCAE2ggDI1gAADgBIKB0AgGAABOoIEwNHoGAABwHJkBAIATGE0QGsEAAMChYCCcngHFLMoEAAA4jswAAMAJjCYIjWAAAOAEk+UPJ9PvU+yiTAAAgOPIDAAAnECZIDSCAQCAG6gThEQwAABwQ5iZAcVwZoCeAQAAHEdmAADgBGYgDI1gAADgBBoIQ6NMAACA48gMAADcYO7saSA8LjIDAACnegbCWQojLy9Po0ePVqNGjVS2bFmddNJJuueee+Q74kDm6zFjxqhWrVp2my5dumjjxo1Bx9mzZ4969+6tlJQUVa5cWX379tXBgwcVSQQDAAAUgX/84x+aNm2aHnvsMa1fv96+nzBhgh599NHANub9lClTNH36dC1fvlzly5dXt27dlJmZGdjGBALr1q3T/PnzNXfuXC1evFg33XRTRM+VMgEAwA3FPOnQ0qVLdemll+riiy+27xs2bKiXXnpJK1asyD+cz6fJkyfrzjvvtNsZL7zwgmrWrKk5c+boqquuskHEvHnz9Mknn6hdu3Z2GxNMdO/eXQ899JBq166tSCAzAABwajRBOIuRkZERtGRlZel4zj77bC1YsEBff/21ff/ZZ5/po48+0kUXXWTfb968WTt37rSlAb9KlSqpffv2WrZsmX1vXk1pwB8IGGb7uLg4m0ko1szAm2++WeADXnLJJeGcDwAAJVq9evWC3t91110aO3bsMduNHDnSBgvNmjVTfHy87SG47777bNrfMIGAYTIBRzLv/evMa40aNYLWJyQkqEqVKoFtii0Y6NmzZ4EO5vF47A8LAECJFIGJg9LT020zn19SUtJxt3v11Vc1c+ZMzZo1Sy1bttSaNWs0ePBgm9rv06ePSpICBQNer7fozwQAgFIw6VBKSkpQMBDKsGHDbHbA1P6NVq1a6fvvv9f48eNtMJCWlmY/37Vrlx1N4Gfet2nTxn5tttm9e3fQcXNzc+0IA//+Ue8ZOLLbEQCAUtFAGM5SCIcPH7a1/SOZcoH/BtsMOTQXdNNX4GfKCqYXoEOHDva9ed23b59WrVoV2GbhwoX2GKa3IGrBgCkDmHGSderUUYUKFfTtt9/az81YymeeeSZiJwYAQGnWo0cP2yPw9ttv67vvvtPs2bM1ceJEXXbZZYHSuikb3HvvvbY3b+3atbruuutsGcFfnm/evLkuvPBC9evXz45CWLJkiQYOHGizDZEaSXBCwYD5wWbMmGHHRiYmJgY+P/XUU/X0009H7MQAAIgsTwSWgjNDAHv16qWbb77ZXtRvv/12/fWvf7U31H7Dhw/XoEGD7LwBZ555pp1MyAwlTE5ODmxj+g5ME2Lnzp3tkMJzzz1XTz75pCLJ4ztyKqQCOPnkk/XEE0/Yk6pYsaIdKtG4cWN99dVXNp2xd+9eFReTTjHDMH7c0FApFRklidjUvW7baJ8CUGRyfTn6r2+O9u/fX6A6fDjXinrTxiqu7K8X2cLy/pyp9P5ji/Rco6XQV9Bt27bZgOBopn6Rk5MTqfMCAAAlNRho0aKFPvzww2M+/9e//qXTTz89UucFAECpbiAsTQo9HbF5oIIZEmEyBCYb8MYbb2jDhg12CkUzZzIAACUSTy2MXGbAzJ/81ltv6YMPPrAPVDDBgZk72Xz2hz/8obCHAwAAUXZCDyo677zz7NOTAAAoLU7kMcRHCmffku6En1q4cuVKmxHw9xG0bUvHMwCgBCvmpxbGdDCwdetWXX311XbiA/MkJcPMjmSezvTyyy+rbt26RXGeAACgpPQM/OUvf7FDCE1WwMyNbBbztWkmNOsAACjRDYThLDGq0JmBRYsWaenSpWratGngM/O1mWnJ9BIAAFASeXz5Szj7x6qEE3mO8/EmFzLPLIjkPMkAAEQUPQORKxM8+OCDdh5l00DoZ76+9dZb9dBDDxX2cAAAoDRkBlJTU+3TlfwOHTpkH52YkJAQeLay+frGG28MPGkJAIAShUmHwgsGJk+eXJDNAAAouSgThBcMmOmHAQBAbDrhSYeMzMxMZWdnB30Wa491BADECDIDkWsgNP0CAwcOVI0aNeyzCUw/wZELAAAlEk8tjFwwMHz4cC1cuFDTpk1TUlKSnn76aY0bN84OKzRPLgQAADFeJjBPJzQX/U6dOumGG26wEw2dfPLJatCggWbOnKnevXsXzZkCABAORhNELjNgph9u3LhxoD/AvDfOPfdcLV68uLCHAwCgWGcgDGeJVYUOBkwgsHnzZvt1s2bN9OqrrwYyBv4HFwEAgBgOBkxp4LPPPrNfjxw5UlOnTlVycrKGDBmiYcOGFcU5AgAQPhoII9czYC76fl26dNFXX32lVatW2b6B0047rbCHAwAApXmeAcM0DpoFAICSzLT/hfXUQjkeDEyZMqXAB7zlllvCOR8AAFASg4FJkyYV6GDmYUbRCAZ6NW2tBE+ZYv++QHF4b/un0T4FoMhkHPAqtUkxfTOGFoYXDPhHDwAAUGoxHXHkRhMAAIDYEnYDIQAApQKZgZAIBgAATgh3FkFPDAcDlAkAAHAcmQEAgBsoE0Q2M/Dhhx/qz3/+szp06KBt27bZz1588UV99NFHJ3I4AACKHtMRRy4YeP3119WtWzeVLVtWn376qbKysuzn+/fv1/3331/YwwEAgNIWDNx7772aPn26nnrqKZUp8+tEP+ecc45Wr14d6fMDACAieIRxBHsGNmzYoI4dOx7zeaVKlbRv377CHg4AgOLBDISRywykpaVp06ZNx3xu+gUaN25c2MMBAFA86BmIXDDQr18/3XrrrVq+fLl9FsH27ds1c+ZM3X777erfv39hDwcAAEpbmWDkyJHyer3q3LmzDh8+bEsGSUlJNhgYNGhQ0ZwlAABhYtKhCAYDJhtwxx13aNiwYbZccPDgQbVo0UIVKlQo7KEAACg+zDMQ+UmHEhMTbRAAAAAcCwYuuOACmx0IZeHCheGeEwAAkRfu8ECfYlahg4E2bdoEvc/JydGaNWv0xRdfqE+fPpE8NwAAIocyQeSCgUmTJh3387Fjx9r+AQAA4OhTC82zCp599tlIHQ4AgMhinoGif2rhsmXLlJycHKnDAQAQUQwtjGAwcPnllwe99/l82rFjh1auXKnRo0cX9nAAAKC0BQPmGQRHiouLU9OmTXX33Xera9eukTw3AABQ0oKBvLw83XDDDWrVqpVSU1OL7qwAAIg0RhNEpoEwPj7e3v3zdEIAQGnDI4wjOJrg1FNP1bffflvY3QAAQKwEA/fee699KNHcuXNt42BGRkbQAgBAiVXMwwq3bdtmh95XrVpVZcuWtWV203AfOB2fT2PGjFGtWrXs+i5dumjjxo1Bx9izZ4969+6tlJQUVa5cWX379o34vD4FDgZMg+ChQ4fUvXt3ffbZZ7rkkktUt25d2ztgFnOC9BEAAEqsYp5nYO/evTrnnHNUpkwZvfvuu/ryyy/18MMPB10rJ0yYoClTpmj69Olavny5ypcvr27duikzMzOwjQkE1q1bp/nz59sb8cWLF+umm26K5L+MPD4TlhSwX8BkAtavX/8/tzv//PNVXEwmwoxu6KRLleApU2zfFyhO721fE+1TAIpMxgGvUpt8q/3799s736K8Vpw84n7FJ534fDh5WZna9I+/F/hcR44cqSVLlujDDz887npz+a1du7Zuu+02m3E3zLFr1qypGTNm6KqrrrLXXPNQwE8++UTt2rWz28ybN8/emG/dutXuX6yjCfwxQ3Fe7AEAKGmTDmUcVRJPSkqyy9HefPNNe5f/pz/9SYsWLVKdOnV08803q1+/fnb95s2btXPnTlsa8DNBS/v27e1EfiYYMK8m8+4PBAyzvRnWbzIJl112mYq9Z+B/Pa0QAAAXygT16tWzF23/Mn78+ON+O9NsP23aNJ1yyil677331L9/f91yyy16/vnn7XoTCBgmE3Ak896/zrzWqFEjaH1CQoKqVKkS2KbY5xlo0qTJbwYEptEBAIBYlZ6eHlQmOF5WwPB6vfaO/v7777fvTz/9dPuEX9MfUNKe8luoYGDcuHHHzEAIAIBLZYKUlJQC9QyYEQKm3n+k5s2b6/XXX7dfp6Wl2dddu3bZbf3M+zZt2gS22b17d9AxcnNz7Y23f/9iDwZM/eLodAUAAKVCMc9AeM4552jDhg1Bn3399ddq0KCB/bpRo0b2gr5gwYLAxd/0I5heAFNSMDp06GAn+lu1apXatm1rP1u4cKHNOpjegmIPBugXAACg4IYMGaKzzz7blgmuvPJKrVixQk8++aRd/NfVwYMH2/l7TF+BCQ7MA//MCIGePXsGMgkXXnihbTo05YWcnBwNHDjQ3pxHaiTBCY0mAACgVCrmzMCZZ56p2bNna9SoUXauHnOxnzx5sp03wG/48OF2Dh8zb4DJAJx77rl26GBy8q9DIGfOnGkDgM6dO9tRBFdccYWdmyAq8wyURMwzABcwzwBiWXHOM9B0SPjzDGyYVPB5BmL6EcYAAJRKPLUwcs8mAAAAsYXMAADADWQGQiIYAAA4IVLzDMQiygQAADiOzAAAwA2UCUIiGAAAOIEyQWiUCQAAcByZAQCAGygThEQwAABwA8FASJQJAABwHJkBAIATzLN3w3n+rkexi2AAAOAGygQhEQwAAJzA0MLQ6BkAAMBxZAYAAG6gTBASwQAAwB0xfEEPB2UCAAAcR2YAAOAEGghDIxgAALiBnoGQKBMAAOA4MgMAACdQJgiNYAAA4AbKBCFRJgAAwHFkBgAATqBMEBrBAADADZQJQiIYAAC4gWAgJHoGAABwHJkBAIAT6BkIjWAAAOAGygQhUSYAAMBxZAYAAE7w+Hx2CWf/WEUwAABwA2WCkCgTAADgODIDAAAnMJogNIIBAIAbKBOERJkAAADHkRkAADiBMkFoBAMAADdQJgiJYAAA4AQyA6HRMwAAgOPIDAAA3ECZICSCAQCAM2I51R8OygQAADiOzAAAwA3mQUPhPGzIF7tpBYIBAIATGE0QGmUCAAAcR2YAAOAGRhOERDAAAHCCx5u/hLN/rKJMAACA4wgGcIy4OJ+uG7ZDz3+8Xm9+87meW7pe1wzeFZQjq1wtR7dN2qJZq9fp3998rvtmfqvajbKiet6Asfbj8hpzXSNdfXpLdavdRkvfrRS0/sWH0tT3vGa65KRWuqL5qRpx5Un6anW5oG0y9sbrgQH1dVmTVrq8WStNHFpPPx+KCzqGOfbRizkmSkGZIJzlBD3wwAPyeDwaPHhw4LPMzEwNGDBAVatWVYUKFXTFFVdo1y7zt/ZXW7Zs0cUXX6xy5cqpRo0aGjZsmHJzcxVplAlwjCsH7NYf+/ykh26tr+83JOuU1od126R0HToQp38/U93+P+KuZ79TXq5HY29opMMH43T5TT/ogVe+Ub/zmyrr5/ho/whwWObhODVu+bO6Xb1Hd/dtdMz6Oo0zNeC+rarVIFtZmXGa/WR1jbr6JD239EtVrppnt/nHwAbas6uMxr/8jXJzPHp4aH1NHlZPox7/3q7v1X+3Lr7ux6DjmqCiaZufi+mnRGkaTfDJJ5/oiSee0GmnnRb0+ZAhQ/T222/rtddeU6VKlTRw4EBdfvnlWrJkiV2fl5dnA4G0tDQtXbpUO3bs0HXXXacyZcro/vvvV8xkBhYvXqwePXqodu3aNmKaM2dONE8Hv2jR7pCWvVdJKxakaNfWRH30dmWtXlRRTdsctuvrNM5Wi3aH9ejIuvr6s3La+k2y/Top2acLLtsX7dOH4878/QFdP2Knzrlo/3HX//7yfTqj40EbDDRsmqmbxm7T4QPx2vxlWbt+y8YkrfxPioY8vEXNzjisU9sf0s33btWif1fWTzvz75/KlveqSo3cwLL3hwRt+bqsul39U7H+rDjBeQbCWSRlZGQELVlZobOiBw8eVO/evfXUU08pNTU18Pn+/fv1zDPPaOLEifr973+vtm3b6rnnnrMX/Y8//thu8/777+vLL7/UP//5T7Vp00YXXXSR7rnnHk2dOlXZ2dmxEwwcOnRIrVu3tj8YSo4vV5ZXm3MPqE7j/F/wxi1+VsuzDumThSn2fZnE/C6a7CxPYB+fz6OcbI9annkoSmcNFJ75nX3nn1VVPiXP/p4b61eWV4VKuWrS+te7/DPOOyBPnPTVp+WPe5x5s6qqbuNMtWrP778L6tWrZ+/k/cv48eNDbmvKAObuvkuXLkGfr1q1Sjk5OUGfN2vWTPXr19eyZcvse/PaqlUr1axZM7BNt27dbACybt262CkTmCjHLAVloq8jIzDzD4LIe+WxGipXMU9PL/5K3jwpLl6a8UCa/jM7P6pN35SsXVvL6MZRO/TIiLo2LXv5TT+qeu0cVamZE+3TB37Tx/NTNL5/A2X9HGd/Z8e/vEmVfikR7PkhQZWrBtdk4xOkipVztWf3sX8yszM9Wjg7Vf83YHexnT+iWyZIT09XSkr+zZGRlJR03O1ffvllrV692pYJjrZz504lJiaqcuXKQZ+bC79Z59/myEDAv96/ztmeARN9jRs3LtqnEfM6XrLPplJNA5XpGTip5c/627jt+mlXGX3wWhXbK3B334YaOjFdr69fp7xc6dMPK2rFgory/JosAEqsNucc1OPzNyhjT4LenVlV9/21oaa8vVGVqxW+MWvJu5X088F4/eHKPUVyrih58wykpKQEBQPHYwKGW2+9VfPnz1dycrJKulI1mmDUqFG2zuJfzD82Iq/f6B02O7Do36n67quyWvB6Fb3xVHVdNejXO59Na8vp5j801WVNT9XVbVrqjt6NlZKapx1bEqN67kBBJJfzqk6jbDVve9gGtebOf95LVey6KtVzte+n4PskE/Ae2Jdg+wOONu+lqmrfZb9Sq0e+wxul16pVq7R7926dccYZSkhIsMuiRYs0ZcoU+7W5wzd1/337gvuszGgC0zBomNejRxf43/u3cTIYMKkYf0RWkMgMJyYp2SvfUZNrmHKB5zj5NdN4tX9Pgh1WaEYdmMZDoLQxv+85Wfl/Dpu3O6SD+xO08fP8hkJjzUcV7TbNTg/uCdi5JVGfLalgRy6g9JQJwlkKqnPnzlq7dq3WrFkTWNq1a2ebCf1fm1EBCxYsCOyzYcMGO5SwQ4cO9r15NccwQYWfyTSYa1+LFi3kbJkAxVdPveqW3dq9LTG/THDqz7r8rz/o/Zfz75yM8/64T/t/StDubWXUqHmm/nb3Ni2bV8mOOgCiycwHsH3zrzXcnemJ+uaLsrbmn1IlT7MeqakOXffbXgFTJnjzuWr6cWcZndcj/w6t/ilZandBhibfXk+D/rFVeTkeTb2zjs6/dJ+qpgXf/b/3chV7nDN/T/9SqVCMTy2sWLGiTj311KDPypcvb+cU8H/et29fDR06VFWqVLEX+EGDBtkA4He/+51d37VrV3vRv/baazVhwgTbJ3DnnXfapsRQfQonimAAx3j8zjrqM3ynBo7fahupTK/AOy9W1cxJvzaymD+Afx273dZYTVPVB6+latbk4EYXIBrMcNfhvU4OvH9ibB37amr6tzyQrq2bknTPaw1tIFAxNU9NWh/Ww7M32mGGfiMe+15T76irkVeeZEcRnNt9n26+d1vQ9/F6pfdfqWKPG8/UGjgBkyZNUlxcnJ1syDTHm5ECjz/+eGB9fHy85s6dq/79+9sgwQQTffr00d13361I8/h80XtAsxl/uWnTJvv16aefbsdbXnDBBTZKMsMrfosZTWCGdXTSpUrwlCmGMwaK33vb10T7FIAik3HAq9Qm39o+sKIq/fqvFR0uulsJZU68mS83J1PL3h1TpOcaLVHNDKxcudJe/P1MusQwkc+MGTOieGYAgJjDUwtLZjDQqVMnRTExAQAAoh0MAAAQ688mKA0IBgAAbvD68pdw9o9RBAMAADfQMxAbkw4BAIDIIzMAAHCCeXRKWD0Dil0EAwAANxTjDISlDWUCAAAcR2YAAOAEhhaGRjAAAHADowlCokwAAIDjyAwAAJzg8fnsEs7+sYpgAADgBu8vSzj7xyjKBAAAOI7MAADACZQJQiMYAAC4gdEEIREMAADcwAyEIdEzAACA48gMAACcwAyEoREMAADcQJkgJMoEAAA4jswAAMAJHm/+Es7+sYpgAADgBsoEIVEmAADAcWQGAABuYNKhkAgGAABOYDri0CgTAADgODIDAAA30EAYEsEAAMAN5loezvBAn2IWwQAAwAn0DIRGzwAAAI4jMwAAcGhoYTg9A4pZBAMAADfQQBgSZQIAABxHZgAA4AYzksAT5v4ximAAAOAERhOERpkAAADHkRkAALiBBsKQCAYAAG4gGAiJMgEAAI4jMwAAcAOZgZAIBgAAbmBoYUgEAwAAJzC0MDR6BgAAcByZAQCAG+gZCIlgAADgBq/P5PrD2z9GUSYAAMBxZAYAAG6gTBASmQEAgCN+CQZOdFHhgoHx48frzDPPVMWKFVWjRg317NlTGzZsCNomMzNTAwYMUNWqVVWhQgVdccUV2rVrV9A2W7Zs0cUXX6xy5crZ4wwbNky5ubmKJIIBAACKwKJFi+yF/uOPP9b8+fOVk5Ojrl276tChQ4FthgwZorfeekuvvfaa3X779u26/PLLA+vz8vJsIJCdna2lS5fq+eef14wZMzRmzJiInqvH5yu9eY+MjAxVqlRJnXSpEjxlon06QJF4b/uaaJ8CUGQyDniV2uRb7d+/XykpKUV6rejSaJAS4pJO+Di53ix9sPnREz7XH374wd7Zm4t+x44d7XGqV6+uWbNmqVevXnabr776Ss2bN9eyZcv0u9/9Tu+++67++Mc/2iChZs2adpvp06drxIgR9niJiYmKBDIDAAA3mNEA4S7KDy6OXLKysgr07c3F36hSpYp9XbVqlc0WdOnSJbBNs2bNVL9+fRsMGOa1VatWgUDA6Natm/2+69ati9g/DcEAAACFUK9ePZtp8C+mN+C3eL1eDR48WOecc45OPfVU+9nOnTvtnX3lypWDtjUXfrPOv82RgYB/vX9dpDCaAADgBp83fwlnf0np6elBZYKkpN8uPZjegS+++EIfffSRSiKCAQCAGyI0tDAlJaVQPQMDBw7U3LlztXjxYtWtWzfweVpamm0M3LdvX1B2wIwmMOv826xYsSLoeP7RBv5tIoEyAQDADRHqGSgo059vAoHZs2dr4cKFatSoUdD6tm3bqkyZMlqwYEHgMzP00Awl7NChg31vXteuXavdu3cHtjEjE0ww0qJFC0UKmQEAAIqAKQ2YkQL//ve/7VwD/hq/6TMoW7asfe3bt6+GDh1qmwrNBX7QoEE2ADAjCQwzFNFc9K+99lpNmDDBHuPOO++0xy5IeaKgCAYAAG4o5hkIp02bZl87deoU9Plzzz2n66+/3n49adIkxcXF2cmGzKgEM1Lg8ccfD2wbHx9vSwz9+/e3QUL58uXVp08f3X333YokggEAgBvsJILhBAMq3OYF+F7JycmaOnWqXUJp0KCB3nnnHRUlegYAAHAcmQEAgBt4UFFIBAMAADd4zTwB3jD3j02UCQAAcByZAQCAGygThEQwAABwA8FASJQJAABwHJkBAIAb7HTCYdzde2M3M0AwAABwgs/ntUs4+8cqggEAgBtMzT+cu3tf7GYG6BkAAMBxZAYAAG6wd/ZkBo6HYAAA4AYzg6AnjLq/L3Z7BigTAADgODIDAAA3UCYIiWAAAOAEn9crXxhlAh9lAgAAEKvIDAAA3ECZICSCAQCAG8yEQx6CgeOhTAAAgOPIDAAA3GDv7MOZZ8CnWEUwAABwgs/rky+MMoGPYAAAgFLODg1kBsLjoWcAAADHkRkAADiBMkFoBAMAADdQJojNYMAfpeUqJ6x5JICSLONA7P4BAjIOeovtrjvca0Wu2T9Glepg4MCBA/b1I70T7VMBikxqk2ifAVA8f88rVapUJMdOTExUWlqaPtoZ/rUiLS3NHi/WeHyluAji9Xq1fft2VaxYUR6PJ9qn44SMjAzVq1dP6enpSklJifbpABHF73fxM5cgEwjUrl1bcXFF19OemZmp7OzssI+TmJio5ORkxZpSnRkwvzh169aN9mk4yfyh5I8lYhW/38WrqDICRzIX8Fi8iEcKQwsBAHAcwQAAAI4jGEChJCUl6a677rKvQKzh9xuuKtUNhAAAIHxkBgAAcBzBAAAAjiMYAADAcQQDAAA4jmAABTZ16lQ1bNjQTtzRvn17rVixItqnBETE4sWL1aNHDzsLnpnNdM6cOdE+JaBYEQygQF555RUNHTrUDrtavXq1WrdurW7dumn37t3RPjUgbIcOHbK/0ybgBVzE0EIUiMkEnHnmmXrssccCz4Uwc7gPGjRII0eOjPbpARFjMgOzZ89Wz549o30qQLEhM4DfZB7usWrVKnXp0iXouRDm/bJly6J6bgCA8BEM4Df9+OOPysvLU82aNYM+N+937twZtfMCAEQGwQAAAI4jGMBvqlatmuLj47Vr166gz837tLS0qJ0XACAyCAbwmxITE9W2bVstWLAg8JlpIDTvO3ToENVzAwCELyECx4ADzLDCPn36qF27djrrrLM0efJkOxzrhhtuiPapAWE7ePCgNm3aFHi/efNmrVmzRlWqVFH9+vWjem5AcWBoIQrMDCt88MEHbdNgmzZtNGXKFDvkECjt/vvf/+qCCy445nMTAM+YMSMq5wQUJ4IBAAAcR88AAACOIxgAAMBxBAMAADiOYAAAAMcRDAAA4DiCAQAAHEcwAACA4wgGAABwHMEAEKbrr79ePXv2DLzv1KmTBg8eHJVZ9Dwej/bt2xdyG7N+zpw5BT7m2LFj7WyT4fjuu+/s9zXT+wIomQgGELMXaHMBMot50NLJJ5+su+++W7m5uUX+vd944w3dc889EbuAA0BR40FFiFkXXnihnnvuOWVlZemdd97RgAEDVKZMGY0aNeqYbbOzs23QEAnm4TYAUJqQGUDMSkpKUlpamho0aKD+/furS5cuevPNN4NS+/fdd59q166tpk2b2s/T09N15ZVXqnLlyvaifumll9o0t19eXp59gqNZX7VqVQ0fPlxHP97j6DKBCUZGjBihevXq2XMyWYpnnnnGHtf/cJzU1FSbITDn5X9E9Pjx49WoUSOVLVtWrVu31r/+9a+g72MCnCZNmtj15jhHnmdBmfMyxyhXrpwaN26s0aNHKycn55jtnnjiCXv+Zjvz77N///6g9U8//bSaN2+u5ORkNWvWTI8//nihzwVA9BAMwBnmomkyAH4LFizQhg0bNH/+fM2dO9deBLt166aKFSvqww8/1JIlS1ShQgWbYfDv9/DDD9un2D377LP66KOPtGfPHs2ePft/ft/rrrtOL730kn3K4/r16+2F1RzXXFxff/11u405jx07duiRRx6x700g8MILL2j69Olat26dhgwZoj//+c9atGhRIGi5/PLL1aNHD1uL/8tf/qKRI0cW+t/E/Kzm5/nyyy/t937qqac0adKkoG3Mo31fffVVvfXWW5o3b54+/fRT3XzzzYH1M2fO1JgxY2xgZX6++++/3wYVzz//fKHPB0CUmKcWArGmT58+vksvvdR+7fV6ffPnz/clJSX5br/99sD6mjVr+rKysgL7vPjii76mTZva7f3M+rJly/ree+89+75WrVq+CRMmBNbn5OT46tatG/hexvnnn++79dZb7dcbNmwwaQP7/Y/nP//5j12/d+/ewGeZmZm+cuXK+ZYuXRq0bd++fX1XX321/XrUqFG+Fi1aBK0fMWLEMcc6mlk/e/bskOsffPBBX9u2bQPv77rrLl98fLxv69atgc/effddX1xcnG/Hjh32/UknneSbNWtW0HHuueceX4cOHezXmzdvtt/3008/Dfl9AUQXPQOIWeZu39yBmzt+k3a/5pprbHe8X6tWrYL6BD777DN7F2zulo+UmZmpb775xqbGzd17+/btA+sSEhLUrl27Y0oFfuauPT4+Xueff36Bz9ucw+HDh/WHP/wh6HOTnTj99NPt1+YO/MjzMDp06KDCeuWVV2zGwvx8Bw8etA2WKSkpQdvUr19fderUCfo+5t/TZDPMv5XZt2/fvurXr19gG3OcSpUqFfp8AEQHwQBilqmjT5s2zV7wTV+AuXAfqXz58kHvzcWwbdu2Nu19tOrVq59waaKwzHkYb7/9dtBF2DA9B5GybNky9e7dW+PGjbPlEXPxfvnll20ppLDnasoLRwcnJggCUDoQDCBmmYu9adYrqDPOOMPeKdeoUeOYu2O/WrVqafny5erYsWPgDnjVqlV23+Mx2QdzF21q/aaB8Wj+zIRpTPRr0aKFvehv2bIlZEbBNOv5myH9Pv74YxXG0qVLbXPlHXfcEfjs+++/P2Y7cx7bt2+3AZX/+8TFxdmmy5o1a9rPv/32WxtYACidaCAEfmEuZtWqVbMjCEwD4ebNm+08ALfccou2bt1qt7n11lv1wAMP2Il7vvrqK9tI97/mCGjYsKH69OmjG2+80e7jP6ZpyDPMxdiMIjAljR9++MHeaZvU++23326bBk0TnknDr169Wo8++migKe9vf/ubNm7cqGHDhtl0/axZs2wjYGGccsop9kJvsgHme5hywfGaIc0IAfMzmDKK+Xcx/x5mRIEZqWGYzIJpeDT7f/3111q7dq0d0jlx4sRCnQ+A6CEYAH5hhs0tXrzY1shNp765+za1cNMz4M8U3Hbbbbr22mvtxdHUzs2F+7LLLvufxzWlil69etnAwQy7M7X1Q4cO2XWmDGAupmYkgLnLHjhwoP3cTFpkOvLNRdachxnRYMoGZqihYc7RjEQwAYYZdmhGHZgu/sK45JJLbMBhvqeZZdBkCsz3PJrJrph/j+7du6tr16467bTTgoYOmpEMZmihCQBMJsRkM0xg4j9XACWfx3QRRvskAABA9JAZAADAcQQDAAA4jmAAAADHEQwAAOA4ggEAABxHMAAAgOMIBgAAcBzBAAAAjiMYAADAcQQDAAA4jmAAAAC57f8BcSudiqP/fhEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Make an inference function (audio_path, model.h5) -> real or fake with percentage (0.89)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mUsers\u001b[49m/hudakhaleel/sentinelai/sentinelai/dataset/fake/file9.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav()\n",
      "\u001b[31mNameError\u001b[39m: name 'Users' is not defined"
     ]
    }
   ],
   "source": [
    "#Make an inference function (audio_path, model.h5) -> real or fake with percentage (0.89)\n",
    "/Users/hudakhaleel/sentinelai/sentinelai/dataset/fake/file9.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (4201685045.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel.load(path=)\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected argument value expression\n"
     ]
    }
   ],
   "source": [
    "model.load(path=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully \n"
     ]
    }
   ],
   "source": [
    "#Make an inference function (audio_path, model.h5) -> real or fake with percentage (0.89)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your saved CNN model\n",
    "model = load_model(\"deepfake_audio_cnn.h5\")\n",
    "\n",
    "print(\"Model loaded successfully \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(audio_path, model):\n",
    "    import librosa, numpy as np\n",
    "    \n",
    "    # Load audio\n",
    "    y, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # Extract MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc = np.mean(mfcc.T, axis=0)  # average over time\n",
    "    mfcc = mfcc.reshape(1, -1)      # reshape for model\n",
    "    \n",
    "    # Predict\n",
    "    prob = model.predict(mfcc)[0][0]  \n",
    "    label = \"Fake\" if prob > 0.5 else \"Real\"\n",
    "    \n",
    "    print(f\"Prediction: {label} ({prob:.2f} confidence)\")\n",
    "    return label, prob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Prediction: Fake (1.00 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Prediction: Real (0.21 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction: Fake (0.91 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Prediction: Real (0.18 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Prediction: Real (0.34 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Prediction: Fake (0.71 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Prediction: Real (0.41 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Prediction: Real (0.41 confidence)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Real', np.float32(0.40681636))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_audio(\"/Users/hudakhaleel/sentinelai/sentinelai/dataset/fake/file6.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\", model)\n",
    "predict_audio(\"/Users/hudakhaleel/sentinelai/sentinelai/dataset/real/file2.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-norm/for-norm/validation/fake/file5.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-rerec/for-rerecorded/testing/real/recording13532.wav_norm_mono.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-rerec/for-rerecorded/testing/fake/recording13017.wav_norm_mono.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/-7488867614957496932 2.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-2sec/for-2seconds/testing/fake/file2.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-2sec/for-2seconds/testing/fake/file37.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction: Real (0.68 confidence)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/w30c5pr52md7kj9d__bfg6xr0000gn/T/ipykernel_67338/4093095509.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\"/Users/hudakhaleel/Downloads/-7488867614957496932 2.m4a\", sr=16000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Real', 0.6831750273704529)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa, soundfile as sf\n",
    "\n",
    "y, sr = librosa.load(\"/Users/hudakhaleel/Downloads/-7488867614957496932 2.m4a\", sr=16000)\n",
    "sf.write(\"converted.wav\", y, sr)\n",
    "predict_audio(\"converted.wav\", model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(audio_path, model):\n",
    "    import librosa, numpy as np\n",
    "    import soundfile as sf\n",
    "    import os, tempfile\n",
    "\n",
    "    # Always load with librosa (handles wav, mp3, flac, m4a, etc.)\n",
    "    y, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # Save to a temporary WAV (optional, ensures consistent format)\n",
    "    tmp_wav = tempfile.mktemp(suffix=\".wav\")\n",
    "    sf.write(tmp_wav, y, sr)\n",
    "\n",
    "    # Reload the clean WAV (consistent for feature extraction)\n",
    "    y, sr = librosa.load(tmp_wav, sr=16000)\n",
    "\n",
    "    # Extract MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc = np.mean(mfcc.T, axis=0)\n",
    "    mfcc = mfcc.reshape(1, -1)\n",
    "\n",
    "    # Predict\n",
    "    probs = model.predict(mfcc)[0]    # e.g., [0.2, 0.8]\n",
    "    classes = [\"Real\", \"Fake\"]\n",
    "    label = classes[np.argmax(probs)]\n",
    "    confidence = float(np.max(probs))\n",
    "\n",
    "    print(f\"Prediction: {label} ({confidence:.2f} confidence)\")\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Prediction: Real (1.00 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Prediction: Real (0.21 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Prediction: Real (0.91 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Prediction: Real (0.18 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Prediction: Real (0.34 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction: Real (0.06 confidence)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Prediction: Real (0.68 confidence)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/w30c5pr52md7kj9d__bfg6xr0000gn/T/ipykernel_67338/124054854.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_path, sr=16000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Real', 0.6831750273704529)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_audio(\"/Users/hudakhaleel/sentinelai/sentinelai/dataset/fake/file6.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\", model)\n",
    "predict_audio(\"/Users/hudakhaleel/sentinelai/sentinelai/dataset/real/file2.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-norm/for-norm/validation/fake/file5.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-rerec/for-rerecorded/testing/real/recording13532.wav_norm_mono.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-rerec/for-rerecorded/testing/fake/recording13017.wav_norm_mono.wav\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/LibriSpeech/dev-clean/84/121123/84-121123-0002.flac\",model)\n",
    "predict_audio(\"/Users/hudakhaleel/Downloads/archive/for-2sec/for-2seconds/testing/fake/file2.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
